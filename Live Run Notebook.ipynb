{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 22:36:22.486668: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortfall in listed houses detected, appending 114 of current listing to results.\n"
     ]
    }
   ],
   "source": [
    "import BHU\n",
    "import os\n",
    "import numpy as np\n",
    "import keys as k\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "keys = k.getKeys()\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "user_home = BHU.get_UserHome(keys['SampleHouse'].strip(\"\\'\"))\n",
    "user_home_details = BHU.get_PropertyDetail(str(user_home['property_id']))\n",
    "hoi = BHU.get_HousesOfInterest(user_home, n=2000, listed_to_sold_ratio=0.3, verbose=True)\n",
    "gd = BHU.GeoData(hoi['geo'])\n",
    "\n",
    "fg = BHU.FeatureGenerator(\n",
    "    houses = hoi['houses'],\n",
    "    gd=gd,\n",
    "    user_home=user_home_details\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the walkscore model exist?\n",
    "import pickle\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pandas as pd\n",
    "\n",
    "model_name = f'{fg.user_home_formatted.city}_{fg.user_home_formatted.state}'\n",
    "model_file_path = f'BHU/Saved Results/WalkScoreModel/{model_name}.pkl'\n",
    "\n",
    "if os.path.isfile(model_file_path):\n",
    "    with open(model_file_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "else:\n",
    "    print(f'No model found, generating {model_name}.')\n",
    "    fg._sync_walk_score()\n",
    "    lat = pd.Series([l.lat_long[0] for l in fg.houses])\n",
    "    long = pd.Series([l.lat_long[1] for l in fg.houses])\n",
    "    ws = pd.Series([l.walk_score for l in fg.houses])\n",
    "\n",
    "    lat_ss = SimpleImputer().fit_transform(np.array(lat).reshape(-1,1))\n",
    "    long_ss = SimpleImputer().fit_transform(np.array(long).reshape(-1,1))\n",
    "    ws_ss = SimpleImputer().fit_transform(np.array(ws).reshape(-1,1))\n",
    "\n",
    "    lat_ss = [z[0] for z in lat_ss]\n",
    "    long_ss = [z[0] for z in long_ss]\n",
    "    ws_ss = [z[0] for z in ws_ss]\n",
    "\n",
    "    grf = GradientBoostingRegressor(n_estimators=250, \n",
    "                                    min_samples_split=3, \n",
    "                                    min_samples_leaf=3, \n",
    "                                    max_depth=8)\n",
    "    \n",
    "    data = pd.DataFrame({'lat':lat_ss, 'long':long_ss, 'ws':ws_ss})\n",
    "    model = grf.fit(data.drop('ws', axis=1), data['ws'])\n",
    "    with open(model_file_path, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1 features, but GradientBoostingRegressor is expecting 2 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m lat, lon \u001b[39m=\u001b[39m fg\u001b[39m.\u001b[39mhouses[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mlat_long[\u001b[39m0\u001b[39m], fg\u001b[39m.\u001b[39mhouses[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mlat_long[\u001b[39m1\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m model\u001b[39m.\u001b[39;49mpredict(np\u001b[39m.\u001b[39;49marray([lat, lon])\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:1798\u001b[0m, in \u001b[0;36mGradientBoostingRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1783\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m   1784\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Predict regression target for X.\u001b[39;00m\n\u001b[1;32m   1785\u001b[0m \n\u001b[1;32m   1786\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1796\u001b[0m \u001b[39m        The predicted values.\u001b[39;00m\n\u001b[1;32m   1797\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1798\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1799\u001b[0m         X, dtype\u001b[39m=\u001b[39;49mDTYPE, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m   1800\u001b[0m     )\n\u001b[1;32m   1801\u001b[0m     \u001b[39m# In regression we can directly return the raw value from the trees.\u001b[39;00m\n\u001b[1;32m   1802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raw_predict(X)\u001b[39m.\u001b[39mravel()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:558\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    555\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 558\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    560\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:359\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 359\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    360\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    361\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    362\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 1 features, but GradientBoostingRegressor is expecting 2 features as input."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "lat, lon = fg.houses[0].lat_long[0], fg.houses[0].lat_long[1]\n",
    "\n",
    "model.predict(np.array([lat, lon]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fg\u001b[39m.\u001b[39mhouses[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fg' is not defined"
     ]
    }
   ],
   "source": [
    "fg.houses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the whole data set\n",
    "target_transformer = StandardScaler()\n",
    "train_targets = target_transformer.fit_transform(np.array(fg.targets).reshape(-1,1))\n",
    "train_features = fg.features\n",
    "\n",
    "normalize_cols = ['lot_sqft', 'sqft']\n",
    "bucketize_cols = ['year_built', 'distance_to_home', 'lat_winz', 'long_winz']\n",
    "dummy_cols = ['baths_full', 'baths_3qtr', 'baths_half', 'baths_1qtr', 'garage', 'stories', 'beds']\n",
    "\n",
    "preprocess_data = ColumnTransformer(\n",
    "    [\n",
    "        #('scale', preprocess_min_max_cols, minmax_cols),\n",
    "        ('normalize', StandardScaler(), normalize_cols),\n",
    "        ('bucketize', BHU.KerasTransformers.preprocess_bucketize_col, bucketize_cols),\n",
    "        ('dummy', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), dummy_cols),\n",
    "        ('walkscore', pass, [])\n",
    "    ]\n",
    ")\n",
    "\n",
    "keras_pipeline = Pipeline(\n",
    "    [\n",
    "        ('to_data_frame', BHU.KerasTransformers.ToDataFrame()),\n",
    "        ('preprocess', preprocess_data),\n",
    "        ('keras_model', BHU.KerasModel(user_home, target_transformer))\n",
    "    ]\n",
    ")\n",
    "\n",
    "keras_pipeline.set_params(**{\n",
    "    'keras_model__load_model_if_available' : True,\n",
    "    'keras_model__update_model' : False,\n",
    "    'keras_model__save_model' : False\n",
    "})\n",
    "\n",
    "keras_pipeline.fit(train_features, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(955466.5, 972500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_pred = keras_pipeline.predict(fg.user_features)\n",
    "user_pred[0][0], fg.user_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3416 19th Ave S'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg.user_home_formatted.address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[981661.1]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = fg.user_features.copy()\n",
    "xx['baths_half'] += 1\n",
    "new_worth = keras_pipeline.predict(xx)\n",
    "new_worth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Property_ID': 2949757771,\n",
       " 'Address': None,\n",
       " 'Status': 'sold',\n",
       " 'Days_listed': 0,\n",
       " 'Days_updated': 0,\n",
       " 'baths_full': 2,\n",
       " 'baths_3qtr': 0,\n",
       " 'baths_half': 0,\n",
       " 'baths_1qtr': 0,\n",
       " 'year_built': 1915,\n",
       " 'lot_sqft': 4414,\n",
       " 'sqft': 2500,\n",
       " 'garage': 1,\n",
       " 'stories': 2,\n",
       " 'beds': 3,\n",
       " 'tags': ['city_view',\n",
       "  'community_security_features',\n",
       "  'dining_room',\n",
       "  'dishwasher',\n",
       "  'fireplace',\n",
       "  'hardwood_floors',\n",
       "  'hill_or_mountain_view',\n",
       "  'lake_view',\n",
       "  'ocean_view',\n",
       "  'spa_or_hot_tub',\n",
       "  'view',\n",
       "  'washer_dryer',\n",
       "  'water_view',\n",
       "  'basement',\n",
       "  'garage_1_or_more',\n",
       "  'fruit_trees',\n",
       "  'tennis_court',\n",
       "  'tennis',\n",
       "  'groundscare',\n",
       "  'garage_1'],\n",
       " 'new_construction': False,\n",
       " 'distance_to_home': 0,\n",
       " 'lat': 47.572613,\n",
       " 'long': -122.306358}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg.user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0274155]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worth_change_ratio = new_worth / user_pred\n",
    "worth_change_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[999161.58735752]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_worth_to_user = worth_change_ratio * fg.user_target\n",
    "new_worth_to_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26661.58735752]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worth_delta = new_worth_to_user - fg.user_target\n",
    "worth_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3, 4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test\n",
       "0  (1, 2)\n",
       "1  (3, 4)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'test':[(1,2), (3,4)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
