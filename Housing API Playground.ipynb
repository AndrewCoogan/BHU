{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntry:\\n    import lightrun\\n    lightrun.enable(company_key=keys[\\'LightRunCompanyKey\\'])\\nexcept ImportError as e:\\n    print(\"Error importing Lightrun: \", e)\\n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from retrying import retry\n",
    "from ediblepickle import checkpoint\n",
    "from urllib.parse import quote\n",
    "from typing import Union\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from keys import *\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "keys = getKeys()\n",
    "'''\n",
    "try:\n",
    "    import lightrun\n",
    "    lightrun.enable(company_key=keys['LightRunCompanyKey'])\n",
    "except ImportError as e:\n",
    "    print(\"Error importing Lightrun: \", e)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(stop_max_attempt_number=5)\n",
    "@checkpoint(key=lambda args, kwargs: quote(args[0]) + '.pkl', work_dir='Saved Results/PropertyDetail/')\n",
    "def get_PropertyDetail(property_id : str) -> dict:\n",
    "    if not isinstance(property_id, str):\n",
    "        try:\n",
    "            property_id = str(property_id)\n",
    "        except:\n",
    "            raise Exception('Could not convert input to string.')\n",
    "\n",
    "    url = \"https://us-real-estate.p.rapidapi.com/v2/property-detail\"\n",
    "\n",
    "    querystring = {\n",
    "        \"property_id\": property_id\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": keys['USRealEstate'],\n",
    "        \"X-RapidAPI-Host\": \"us-real-estate.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    return response.json()\n",
    "\n",
    "@retry(stop_max_attempt_number=5)\n",
    "def get_PropertyForSaleByZipcode(zipcode : str, \n",
    "        property_type : str = 'single_family',\n",
    "        n_results : int = 100\n",
    "    ) -> dict:\n",
    "\n",
    "    url = \"https://us-real-estate.p.rapidapi.com/v2/for-sale-by-zipcode\"\n",
    "\n",
    "    # We need to make a loop here and iterate the offset until we hit the end or the limit.\n",
    "    # This is going to take a lot of API calls.\n",
    "\n",
    "    # This can be increased to 200 once we get the paid plan.\n",
    "    limit = min(42, n_results)\n",
    "\n",
    "    '''\n",
    "    Other query string parameters:\n",
    "    sort = (default: relevant)|newest|lowest_price|highest_price|open_house_date|price_reduced_date|largest_sqft|lot_size|sold_date\n",
    "    price_min/max = $ USD\n",
    "    beds_min/max = #\n",
    "    bath_min/max = #\n",
    "    property_type = multi_family|single_family|mobile|land|farm (I think we should just use : 'single_family')\n",
    "    '''\n",
    "\n",
    "    querystring = {\n",
    "        \"zipcode\":zipcode,\n",
    "        \"offset\":\"0\",\n",
    "        \"limit\":str(limit),\n",
    "        \"property_type\":property_type\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": keys['USRealEstate'],\n",
    "        \"X-RapidAPI-Host\": \"us-real-estate.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    output = []\n",
    "\n",
    "    '''\n",
    "    while(True):\n",
    "        response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "        output.append(response.json())\n",
    "\n",
    "        if len(response) < limit\n",
    "    '''\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    return response.json()\n",
    "\n",
    "@retry(stop_max_attempt_number=5)\n",
    "def get_PropertySoldByZipcode(zipcode : str, \n",
    "        n_results : int,\n",
    "        property_type : str = 'single_family'\n",
    "    ) -> dict:\n",
    "    \n",
    "    '''\n",
    "    NOTE: This does not seem to have a limit arguement. I do not know how this works with offset?\n",
    "    '''\n",
    "\n",
    "    url = \"https://us-real-estate.p.rapidapi.com/v2/sold-homes-by-zipcode\"\n",
    "\n",
    "    # This can be increased to 200 once we get the paid plan.\n",
    "    offset = min(42, n_results)\n",
    "\n",
    "    '''\n",
    "    Other query string parameters:\n",
    "    sort = (default: relevant)|newest|lowest_price|highest_price|open_house_date|price_reduced_date|largest_sqft|lot_size|sold_date\n",
    "    price_min/max = $ USD\n",
    "    beds_min/max = #\n",
    "    bath_min/max = #\n",
    "    property_type = multi_family|single_family|mobile|land|farm (I think we should just use : 'single_family')\n",
    "    '''\n",
    "\n",
    "    querystring = {\n",
    "        \"zipcode\":zipcode,\n",
    "        \"offset\":offset,\n",
    "        \"property_type\":property_type\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": keys['USRealEstate'],\n",
    "        \"X-RapidAPI-Host\": \"us-real-estate.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    output = []\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring).json()\n",
    "\n",
    "    return response\n",
    "\n",
    "def get_LocationSuggest(search_keyword : str, \n",
    "        return_all : bool = False\n",
    "    ) -> dict:\n",
    "\n",
    "    url = \"https://us-real-estate.p.rapidapi.com/location/suggest\"\n",
    "\n",
    "    querystring = {\"input\":search_keyword}\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": keys['USRealEstate'],\n",
    "        \"X-RapidAPI-Host\": \"us-real-estate.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    response_json = response.json()\n",
    "\n",
    "    return response_json if return_all else response_json['data'][0]\n",
    "\n",
    "\n",
    "def get_PropertyForSaleByArea(\n",
    "        city : str = '',\n",
    "        state : str = '',\n",
    "        n_results : int = 100 # How many houses do you want to get back.\n",
    "        # Should make a method that if n_results is None, it pulls back everything.\n",
    "    ) -> dict:\n",
    "\n",
    "    # This can be increased to 200 once we move to the paid version.\n",
    "    limit = min(42, n_results)\n",
    "\n",
    "    url = \"https://us-real-estate.p.rapidapi.com/v2/for-sale\"\n",
    "\n",
    "    querystring = {\n",
    "        \"state_code\":state,\n",
    "        \"city\":city,\n",
    "        \"offset\":\"0\",\n",
    "        \"limit\":str(limit),\n",
    "        \"sort\":\"newest\"\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": keys['USRealEstate'],\n",
    "        \"X-RapidAPI-Host\": \"us-real-estate.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring).json()\n",
    "    total_houses_available = int(response['data']['home_search']['total'])\n",
    "    total_houses_in_request = int(response['data']['home_search']['count'])\n",
    "\n",
    "    print(f'Returning {str(min(total_houses_available, n_results))} out of a possible {str(total_houses_available)}.')\n",
    "\n",
    "    geo_to_return = response['data']['geo'] # We know this is the same at each iteration.\n",
    "    houses_to_return = response['data']['home_search']['results']\n",
    "\n",
    "    # Are the returned 'geo' values the same, or do they change when there are offests?\n",
    "    # I want this function to be pure, just returning the raw json info.\n",
    "    # I am thinking we return a dict with two values:\n",
    "    # - meta_data : ['data']['geo']\n",
    "    # - houses : ['data']['home_search']['results']\n",
    "\n",
    "    houses_remaining = min(total_houses_available, n_results) - len(houses_to_return)\n",
    "\n",
    "    while houses_remaining > 0:\n",
    "        querystring['offset'] = str(int(querystring['offset']) + limit)\n",
    "        querystring['limit'] = str(min(limit, houses_remaining))\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers, params=querystring).json()\n",
    "        houses_to_return.extend(response['data']['home_search']['results'])\n",
    "        houses_remaining -= len(response['data']['home_search']['results'])\n",
    "\n",
    "    return {\n",
    "        'houses' : houses_to_return,\n",
    "        'geo' : geo_to_return\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to be digesting two areas of the API return:\n",
    "\n",
    "    - v['data']['geo']\n",
    "    \n",
    "    - v['data']['home_search']['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be taking in the following: tt['data']['geo']\n",
    "class geo_data():\n",
    "    '''\n",
    "    This is going to be used to organize the meta information about each query.\n",
    "    I need to think where it is most appropriate to do this.\n",
    "    '''\n",
    "    def __init__(self, stats : dict):\n",
    "        self.zip_info = self._parse_areas(stats.get('recommended_zips', {}).get('geos'))\n",
    "        self.city_info = self._parse_areas(stats.get('recommended_cities', {}).get('geos'))\n",
    "        self.county_info = self._parse_areas(stats.get('recommended_counties', {}).get('geos'))\n",
    "        self.neighborhood_info = self._parse_areas(stats.get('recommended_neighborhoods', {}).get('geos'))\n",
    "        self.market_stats = self._parse_statistics(stats.get('geo_statistics', {}).get('housing_market'))\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        pass\n",
    "\n",
    "    def _parse_areas(self, geos : dict) -> dict:\n",
    "        return None if geos is None else {\n",
    "            v.get(v.get('geo_type', 'slug_id'), '_parse_areas_FAILED') : {\n",
    "                'slug_id' : v.get('slug_id'),\n",
    "                'median_listing_price' : v.get('geo_statistics', {}).get('housing_market', {}).get('median_listing_price'),\n",
    "                'state_code' : v.get('state_code'),\n",
    "                'city_code' : v.get('city'),\n",
    "                'geo_type' : v.get('geo_type')\n",
    "            } for v in geos\n",
    "        }\n",
    "    \n",
    "    def _parse_statistics(self, geo_stats : dict) -> dict:\n",
    "        return None if geo_stats is None else {\n",
    "            'median_days_on_market' : geo_stats.get('median_days_on_market'),\n",
    "            'median_sold_price' : geo_stats.get('median_sold_price'),\n",
    "            'median_price_per_sqft' : geo_stats.get('median_price_per_sqft'),\n",
    "            'median_listing_price' : geo_stats.get('median_listing_price'),\n",
    "            'month_to_month_metrics' : geo_stats.get('month_to_month'),\n",
    "            'by_prop_type' : {\n",
    "                ht.get('type') : {\n",
    "                    k : v for k, v in ht.get('attributes', {}).items()\n",
    "                } for ht in geo_stats.get('by_prop_type', {})\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be taking in the following: tt['data']['home_search']['results'][n]\n",
    "class house():\n",
    "    '''\n",
    "    This is going to be the class that houses (hehe) all the house data. Each house will have its own instance.\n",
    "    When we use the API, there is a lot of data reutned nested in a number of dictionaries. This will take the 'juicy' bit.\n",
    "    The idea for this class is that it will hold all the needed info for:\n",
    "         1) the GUI, address, google street view, other photos. This will probably be a flask application to start, but we are \n",
    "            far from even thinking about that.\n",
    "         2) the MODEL, tags, list_prices, other flags. What if we created a word cloud and have the user select key words for \n",
    "            their house until they have selected some flat number or % contribution to model from the tags TBD. There will be \n",
    "            dates there, we will use days old (or something similar) for the model training, while the actual took will use zero, \n",
    "            as the user is entering 100% correct info. This may or may not be a good idea, as it might have unintended implications\n",
    "            within the model.\n",
    "\n",
    "    Interior functions:\n",
    "        Date Cleaning\n",
    "        Location Cleaning\n",
    "        Description Cleaning\n",
    "    '''\n",
    "    def __init__(self, listing : list):\n",
    "        self.reference_info = { # This is stuff not going into the model\n",
    "            'id' : listing['property_id'],\n",
    "            'photos' : list(set([listing['primary_photo']['href']] + [l['href'] for l in listing['photos']]))\n",
    "        }\n",
    "\n",
    "        self.raw_last_update = listing['last_update_date']\n",
    "        self.raw_list_date = listing['list_date']\n",
    "        self.tags = listing['tags']\n",
    "        self.list_price = listing['list_price']\n",
    "        self.new_construction = listing.get('flags', {}).get('is_new_construction', False) or False\n",
    "\n",
    "        self.raw_location = listing['location']\n",
    "        self.raw_description = listing['description']\n",
    "\n",
    "        self._clean_dates()\n",
    "        self._clean_location()\n",
    "        self._clean_description()\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        pass\n",
    "        \n",
    "    def _convert_date(self, date : str) -> datetime:\n",
    "        return datetime.strptime(date, '%Y-%m-%d')\n",
    "    \n",
    "    def _clean_dates(self) -> None:\n",
    "        last_update_date_parsed = self.raw_last_update.split('T')\n",
    "        list_date_parsed = self.raw_list_date.split('T')\n",
    "        self.last_update = self._convert_date(last_update_date_parsed[0]) if len(last_update_date_parsed) == 2 else None\n",
    "        self.list_date = self._convert_date(list_date_parsed[0]) if len(list_date_parsed) == 2 else None\n",
    "        self.last_update_delta = None if self.last_update is None else max((datetime.now() - self.last_update).days, 0)\n",
    "        self.list_date_delta = None if self.list_date is None else max((datetime.now() - self.list_date).days, 0)\n",
    "        \n",
    "    def _clean_location(self) -> None:\n",
    "        self.reference_info.update({\n",
    "            'zip_code' : self.raw_location.get('address', {}).get('postal_code'),\n",
    "            'state' : self.raw_location.get('address', {}).get('state'),\n",
    "            'google_map_street_view' : self.raw_location.get('street_view_url'),\n",
    "            'fips_code' : self.raw_location.get('county', {}).get('fips_code'),\n",
    "            'county' : self.raw_location.get('county', {}).get('county')\n",
    "        })\n",
    "\n",
    "        lat_long = self.raw_location.get('address', {}).get('coordinate')\n",
    "        self.lat_long = (None, None) if lat_long is None else (lat_long.get('lat'), lat_long.get('lon'))     \n",
    "\n",
    "    def _clean_description(self) -> None:\n",
    "        self.baths_full = self.raw_description.get('baths_full') or 0\n",
    "        self.baths_3qtr = self.raw_description.get('baths_3qtr') or 0\n",
    "        self.baths_half = self.raw_description.get('baths_half') or 0\n",
    "        self.baths_1qtr = self.raw_description.get('baths_1qtr') or 0\n",
    "        self.year_built = self.raw_description.get('year_built')\n",
    "        self.lot_sqft = self.raw_description.get('lot_sqft')\n",
    "        self.sqft = self.raw_description.get('sqft')\n",
    "        self.garage = self.raw_description.get('garage') or 0\n",
    "        self.stories = self.raw_description.get('stories') or 1\n",
    "        self.beds = self.raw_description.get('beds')\n",
    "        self.type = self.raw_description.get('type')\n",
    "\n",
    "    def _validate(self):\n",
    "        '''\n",
    "        This will be used to flag anything the looks strange (missing values, etc)\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_as_houses(data : dict) -> dict:\n",
    "    '''\n",
    "    I am going to try and make the outputs of all the API's to be the same.\n",
    "    In my head they should have similar structure, maybe sold houses are differently structured, we will have to see.\n",
    "\n",
    "    This will also transform the house type to a pandas dataframe.\n",
    "\n",
    "    As I do this, I am reminded that we should be thinking again and planning on using pipes.\n",
    "    If we are going to use pipes, we need to think about HOW we are going to implement this from the top down.\n",
    "    Where does the pipeline start? After querying the data? I think thats a fair place to start, but it forces out hands to ensure\n",
    "    the outputs of the functions to be the same.\n",
    "    '''\n",
    "    output = {\n",
    "        'houses' : [house(h) for h in data['houses']],\n",
    "        'geo' : geo_data(data['geo'])\n",
    "    }\n",
    "\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToDataFrame(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X) -> pd.DataFrame:\n",
    "        return pd.DataFrame({\n",
    "            'Days_listed' : X.list_date_delta,\n",
    "            'Days_updated' : X.last_update_delta,\n",
    "            'baths_full' : X.baths_full,\n",
    "            'baths_3qtr' : X.baths_3qtr,\n",
    "            'baths_half' : X.baths_half,\n",
    "            'baths_1qtr' : X.baths_1qtr,\n",
    "            'year_built' : X.year_built,\n",
    "            'lot_sqft' : X.lot_sqft,\n",
    "            'sqft' : X.sqft,\n",
    "            'garage' : X.garage,\n",
    "            'stories' : X.stories,\n",
    "            'beds' : X.beds,\n",
    "            'type' : X.type,\n",
    "            'tags' : X.tags,\n",
    "            'lot_long' : X.lat_long,\n",
    "            'new_construction' : X.new_construction\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = house(tt['houses'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max((datetime.now() - test.last_update).days, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = get_PropertyForSaleByArea(city='seattle', state='WA', n_results=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geolocator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-da9ae8288343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeolocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeocode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Chicago'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'geolocator' is not defined"
     ]
    }
   ],
   "source": [
    "tt = geolocator.geocode('Chicago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = {'bb':5,\n",
    "'cc' : {\n",
    "    'dd' : 4,\n",
    "    'ee' : 7\n",
    "}, 'xxx' : 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bb</th>\n",
       "      <th>cc</th>\n",
       "      <th>xxx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>dd</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ee</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bb  cc  xxx\n",
       "dd   5   4    1\n",
       "ee   5   7    1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ab43341cdb9c646b14fa16d0011f2a3e36de46263eb87f9c743def1b75d47a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
